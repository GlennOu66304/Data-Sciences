{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============正在下载第1页的图片===============\n",
      "============第1页的图片下载完成===============\n",
      "==============正在下载第2页的图片===============\n",
      "============第2页的图片下载完成===============\n",
      "==============正在下载第3页的图片===============\n",
      "============第3页的图片下载完成===============\n",
      "==============正在下载第4页的图片===============\n",
      "============第4页的图片下载完成===============\n",
      "==============正在下载第5页的图片===============\n",
      "============第5页的图片下载完成===============\n"
     ]
    }
   ],
   "source": [
    "# 爬取微博 Duebass的图片\n",
    "\n",
    "from urllib import request\n",
    "import re\n",
    "import ssl\n",
    "\n",
    "file_path = '/Users/zhanghuiqiao/Desktop/blog'\n",
    "# http://wallpaper.apc.360.cn/index.php?c=WallPaper&a=getAppsByCategory&cid=6&start=6590&count=50            #uid                          #fid\n",
    "\n",
    "#需要将下面url里面的  uid&value=后面的数字换成所要爬取用户的uid，，还需要将containerid=这个替换成所要爬取用的的fid\n",
    "base_url = 'https://m.weibo.cn/api/container/getIndex?is_hot[]=1&is_hot[]=1&jumpfrom=weibocom&type=uid&value=1312412824&containerid=1076031312412824&page='\n",
    "\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Referer': 'https://m.weibo.cn/u/1312412824'   #这个需要改成所要爬取用户主页的手机版本下的url\n",
    "}\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    try:\n",
    "        realurl = base_url + str(i)\n",
    "        req = request.Request(url=realurl, headers=header)\n",
    "        # resp = requests.get(realurl, headers=header)\n",
    "        resp = request.urlopen(req, context=context).read().decode()\n",
    "        print('==============正在下载第' + str(i) + '页的图片===============')\n",
    "        # 先获取所有的large里面的url，注意观察，大图的url中都包含/large,那么我们获取所有的url然后过虐掉不包含/large的url就行了\n",
    "        pat = '\"url\":\"(.*?)\"'\n",
    "        list1 = re.compile(pat).findall(resp)\n",
    "        list2 = filter(lambda url: url.find('/large') != -1, list1)\n",
    "        list2 = list(list2)\n",
    "        for j in range(0, len(list2) - 1):\n",
    "            pic_url = list2[j].replace('\\/', '/')\n",
    "            request.urlretrieve(pic_url, file_path + str(i) + str(j) + '.jpg')\n",
    "        print('============第' + str(i) + '页的图片下载完成===============')\n",
    "\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
